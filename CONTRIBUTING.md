# Contributing to the Transparent Reasoning Profile

Thank you for your interest in contributing! This framework is designed to support epistemic clarity and transparency in AI reasoning through a lightweight labeling system (F1–F4). While the project is open, contributions should uphold its purpose and integrity.

---

## 🙌 What You Can Contribute

- ✍ **New Case Studies** — Add a markdown case showing how a model uses F1–F4 reasoning on a philosophical, technical, or speculative prompt.
- 🌐 **Language Localizations** — Translate key files (README, labels, profiles) while preserving semantic distinctions.
- ⚙ **Prompt Formats** — Suggest prompt structures or templates for different model families.
- 🧪 **Label Extensions** — Propose new tags (e.g., F5: Contradiction) with clear epistemic function.
- 📚 **Documentation Fixes** — Improve clarity, fix typos, refine structure.

---

## 🧭 Guidelines for Case Contributions

1. Use structured Markdown format (like existing cases in `/cases/`).
2. Apply the F1–F4 tagging faithfully. Do not promote speculative content as factual.
3. Include reasoning and final output. Annotate any metaphors (F4).
4. If the model failed to reason well — that’s OK! Still valuable.

---

## 📥 How to Submit

- Fork the repo
- Add your files in the appropriate folder (`/cases`, `/docs`, etc.)
- Open a pull request (PR)
- Optionally, open an Issue to start a discussion first

---

## 🧾 License Note

All contributions fall under the repository’s [MIT License](./LICENSE) with the attached [Transparency Clause](./LICENSE_ADDENDUM.md).  
You’re contributing to an open epistemic framework — please respect its purpose.

---

## 🤝 Review Process

We welcome respectful, thoughtful participation.  
This project is about reasoning, not authority — so bring questions, ideas, or experiments. If your contribution is aligned with clarity, honesty, and logic — it will be considered with care.

Thank you!  
— Ekaterina Larionova